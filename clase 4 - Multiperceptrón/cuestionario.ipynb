{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29e8e334-1da4-4296-812d-911bee586f65",
   "metadata": {},
   "source": [
    "## EJERCICIOS DEL CUESTIONARIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1c17b0-f52c-4fcc-ae16-912b1376ff69",
   "metadata": {},
   "source": [
    "## pregunta 5 - cuestionario"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce945936-5c23-44c9-9814-69b68e0f42ba",
   "metadata": {},
   "source": [
    "A partir de todos los ejemplos del archivo Vinos.csv se entrenó un multiperceptrón con una sola capa oculta formada por 6 neuronas para predecir el tipo de vino al que pertenece la muestra suministrada. Todos los ejemplos fueron normalizados utilizando media y desvío y empleados para el entrenamiento (no se dividió en entrenamiento y testeo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b713a3a4-dee5-499f-b364-1ce506579775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "402be0b7-23b2-4a36-88b6-f4b081591cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuración para notebook con instalación LOCAL\n",
    "FUENTES_DIR = '../Fuentes' # carpeta donde se encuentran archivos .py auxiliares\n",
    "DATOS_DIR   = '../Datos/'  # carpeta donde se encuentran los datasets\n",
    "\n",
    "# agrega ruta de busqueda donde tenemos archivos .py\n",
    "import sys\n",
    "sys.path.append(FUENTES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "382a1010-d7c0-42e5-8d6b-1b9619e5e992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
      "0        1    14.23        1.71  2.43               15.6        127   \n",
      "1        1    13.20        1.78  2.14               11.2        100   \n",
      "2        1    13.16        2.36  2.67               18.6        101   \n",
      "3        1    14.37        1.95  2.50               16.8        113   \n",
      "4        1    13.24        2.59  2.87               21.0        118   \n",
      "..     ...      ...         ...   ...                ...        ...   \n",
      "173      3    13.71        5.65  2.45               20.5         95   \n",
      "174      3    13.40        3.91  2.48               23.0        102   \n",
      "175      3    13.27        4.28  2.26               20.0        120   \n",
      "176      3    13.17        2.59  2.37               20.0        120   \n",
      "177      3    14.13        4.10  2.74               24.5         96   \n",
      "\n",
      "     Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
      "0             2.80        3.06                  0.28             2.29   \n",
      "1             2.65        2.76                  0.26             1.28   \n",
      "2             2.80        3.24                  0.30             2.81   \n",
      "3             3.85        3.49                  0.24             2.18   \n",
      "4             2.80        2.69                  0.39             1.82   \n",
      "..             ...         ...                   ...              ...   \n",
      "173           1.68        0.61                  0.52             1.06   \n",
      "174           1.80        0.75                  0.43             1.41   \n",
      "175           1.59        0.69                  0.43             1.35   \n",
      "176           1.65        0.68                  0.53             1.46   \n",
      "177           2.05        0.76                  0.56             1.35   \n",
      "\n",
      "     Color intensity   Hue  OD280/OD315  Proline  \n",
      "0               5.64  1.04         3.92     1065  \n",
      "1               4.38  1.05         3.40     1050  \n",
      "2               5.68  1.03         3.17     1185  \n",
      "3               7.80  0.86         3.45     1480  \n",
      "4               4.32  1.04         2.93      735  \n",
      "..               ...   ...          ...      ...  \n",
      "173             7.70  0.64         1.74      740  \n",
      "174             7.30  0.70         1.56      750  \n",
      "175            10.20  0.59         1.56      835  \n",
      "176             9.30  0.60         1.62      840  \n",
      "177             9.20  0.61         1.60      560  \n",
      "\n",
      "[178 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd      # para trabajar con archivos de datos csv, excel, etc: https://pandas.pydata.org/docs/getting_started/tutorials.html\n",
    "#import chardet           # para detectar la codificación de texto en archivos\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "nombre_archivo = DATOS_DIR + 'Vinos.csv' \n",
    "\n",
    "# recupera el archivo en un objeto dataframe de pandas utilizando la codificación detectada\n",
    "df = pd.read_csv(nombre_archivo, sep=';')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c3c3c1d-2bec-4578-820b-fad8cb25cce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las clases del dataset son : [1 2 3]\n",
      "[[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# %% separa atributos y clases\n",
    "X_raw = np.array(df.iloc[:,1:])  # recupera todas las columnas salvo la primera (es la clase)\n",
    "Y_raw = np.array(df.iloc[:,0])    # recupera solo la primer columna (es la clase)\n",
    "\n",
    "# Binarizador para convertir el nombre de la clase en one hot encoding\n",
    "binarizer = preprocessing.LabelBinarizer()\n",
    "\n",
    "# Binariza cada clase como una combinación de un 1 y 0s\n",
    "Y_raw = binarizer.fit_transform(Y_raw)\n",
    "# Y_raw==pd.get_dummies(df[' Balance']).to_numpy() # forma alternativa para codificar\n",
    "\n",
    "print('Las clases del dataset son :', binarizer.classes_)\n",
    "print(Y_raw)\n",
    "\n",
    "########### APLICO NORMALIZACION CON MEDIA Y DESVIO ################3\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_raw  = scaler.fit_transform( X_raw )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a2d45bc8-21a7-47a3-a1d2-03e591b17766",
   "metadata": {},
   "source": [
    "La función de activación seleccionada fue la función ‘relu’, el valor de alfa utilizado fue 0.1, la máxima cantidad de épocas se fijó en 30, la cota de error en 10e-05 y se determinó la generación de números aleatorios para la inicialización de pesos y sesgos asignando al parámetro 'random_state' el valor 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cd316d3-7e1e-4945-8e4e-2453642c0225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efectividad:  93.82%\n",
      "      Score:   0.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\W10\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# f.activacion --> 'relu\n",
    "#alfa = 0.1\n",
    "#CotaError = 10e-5\n",
    "#MAX_ITE = 30\n",
    "\n",
    "modelo= MLPClassifier(solver='sgd', learning_rate_init=0.1,\n",
    "\n",
    "                 hidden_layer_sizes=(6, ), random_state=1,\n",
    "\n",
    "                 max_iter=30, verbose=False,  tol=10e-05,\n",
    "\n",
    "                 activation='relu')\n",
    "\n",
    "modelo.fit(X_raw, Y_raw)\n",
    "\n",
    "\n",
    "#  ########### Medición del entrenamiento ######################\n",
    "# entrenamiento con X_train e Y_train \n",
    "Y_pred = modelo.predict(X_raw)\n",
    "score = modelo.score(X_raw, Y_raw)\n",
    "\n",
    "# \"invierte\" la transformacion binaria para obtener los nombres de las clases\n",
    "Y_it = binarizer.inverse_transform(Y_raw)\n",
    "Y_pred_it = binarizer.inverse_transform(Y_pred)\n",
    "\n",
    "# calculo manual del accuracy\n",
    "print('Efectividad: %6.2f%%' % (100*(Y_pred_it == Y_it).sum()/len(Y_it)) )\n",
    "print('      Score: %6.2f%%' % (score) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19837e0-1391-46c2-b1b7-a8a6e13434f0",
   "metadata": {},
   "source": [
    "### el accuracy es del 93.82% , no del 100%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97997973-e16b-4621-881a-9c3c01fd82f9",
   "metadata": {},
   "source": [
    "### --------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26b236d-9256-4d1d-8869-24b45b552209",
   "metadata": {},
   "source": [
    "### Preguntas 7 y 8 - cuestionario"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b9c3422-3ca1-4d99-9a86-1c7a72cad325",
   "metadata": {},
   "source": [
    "El archivo “mod_HOUSING.h5”, ubicado en la carpeta DATOS,  contiene un modelo capaz de predecir el precio de una vivienda. Fue entrenado con los atributos numéricos de todos los ejemplos del archivo “housing.csv”. Los atributos utilizados fueron: ‘longitude’, ‘latitude’, ‘housing_median_age’, ‘total_rooms’, ‘total_bedrooms’, ‘population’ , ‘households’ y ‘median_income’. El valor predicho corresponde al atributo ‘median_house_value’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7bdfcaff-001b-4f0e-988b-bf813fc94986",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized keyword arguments: ['batch_shape']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13880\\2457580384.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Cargar el modelo desde el archivo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATOS_DIR\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"mod_HOUSING.h5\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'LeakyReLU'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mLeakyReLU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'loss'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Mostrar el resumen del modelo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\p37env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\p37env\\lib\\site-packages\\keras\\engine\\input_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_shape, batch_size, dtype, input_tensor, sparse, name, ragged, type_spec, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             raise ValueError(\n\u001b[1;32m--> 153\u001b[1;33m                 \u001b[1;34mf\"Unrecognized keyword arguments: {list(kwargs.keys())}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m             )\n\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unrecognized keyword arguments: ['batch_shape']"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "# Cargar el modelo desde el archivo\n",
    "model = load_model(DATOS_DIR + \"mod_HOUSING.h5\", custom_objects={'LeakyReLU': LeakyReLU, 'loss': 'mean_squared_error'})\n",
    "\n",
    "# Mostrar el resumen del modelo\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc4fa01",
   "metadata": {},
   "source": [
    "### Si se aplica el modelo a todos los ejemplos de entrenamiento se obtiene un valor del coeficiente de determinación R2 superior a 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d85a7f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0        -122.23     37.88                41.0        880.0           129.0   \n",
      "1        -122.22     37.86                21.0       7099.0          1106.0   \n",
      "2        -122.24     37.85                52.0       1467.0           190.0   \n",
      "3        -122.25     37.85                52.0       1274.0           235.0   \n",
      "4        -122.25     37.85                52.0       1627.0           280.0   \n",
      "...          ...       ...                 ...          ...             ...   \n",
      "20635    -121.09     39.48                25.0       1665.0           374.0   \n",
      "20636    -121.21     39.49                18.0        697.0           150.0   \n",
      "20637    -121.22     39.43                17.0       2254.0           485.0   \n",
      "20638    -121.32     39.43                18.0       1860.0           409.0   \n",
      "20639    -121.24     39.37                16.0       2785.0           616.0   \n",
      "\n",
      "       population  households  median_income  median_house_value  \\\n",
      "0           322.0       126.0         8.3252            452600.0   \n",
      "1          2401.0      1138.0         8.3014            358500.0   \n",
      "2           496.0       177.0         7.2574            352100.0   \n",
      "3           558.0       219.0         5.6431            341300.0   \n",
      "4           565.0       259.0         3.8462            342200.0   \n",
      "...           ...         ...            ...                 ...   \n",
      "20635       845.0       330.0         1.5603             78100.0   \n",
      "20636       356.0       114.0         2.5568             77100.0   \n",
      "20637      1007.0       433.0         1.7000             92300.0   \n",
      "20638       741.0       349.0         1.8672             84700.0   \n",
      "20639      1387.0       530.0         2.3886             89400.0   \n",
      "\n",
      "      ocean_proximity  \n",
      "0            NEAR BAY  \n",
      "1            NEAR BAY  \n",
      "2            NEAR BAY  \n",
      "3            NEAR BAY  \n",
      "4            NEAR BAY  \n",
      "...               ...  \n",
      "20635          INLAND  \n",
      "20636          INLAND  \n",
      "20637          INLAND  \n",
      "20638          INLAND  \n",
      "20639          INLAND  \n",
      "\n",
      "[20640 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# importo csv de datos housing.csv\n",
    "nombre_archivo = DATOS_DIR + 'housing.csv' \n",
    "\n",
    "# recupera el archivo en un objeto dataframe de pandas utilizando la codificación detectada\n",
    "df = pd.read_csv(nombre_archivo, sep=',')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e075e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0        -122.23     37.88                41.0        880.0           129.0   \n",
      "1        -122.22     37.86                21.0       7099.0          1106.0   \n",
      "2        -122.24     37.85                52.0       1467.0           190.0   \n",
      "3        -122.25     37.85                52.0       1274.0           235.0   \n",
      "4        -122.25     37.85                52.0       1627.0           280.0   \n",
      "...          ...       ...                 ...          ...             ...   \n",
      "20635    -121.09     39.48                25.0       1665.0           374.0   \n",
      "20636    -121.21     39.49                18.0        697.0           150.0   \n",
      "20637    -121.22     39.43                17.0       2254.0           485.0   \n",
      "20638    -121.32     39.43                18.0       1860.0           409.0   \n",
      "20639    -121.24     39.37                16.0       2785.0           616.0   \n",
      "\n",
      "       population  households  median_income  median_house_value  \n",
      "0           322.0       126.0         8.3252            452600.0  \n",
      "1          2401.0      1138.0         8.3014            358500.0  \n",
      "2           496.0       177.0         7.2574            352100.0  \n",
      "3           558.0       219.0         5.6431            341300.0  \n",
      "4           565.0       259.0         3.8462            342200.0  \n",
      "...           ...         ...            ...                 ...  \n",
      "20635       845.0       330.0         1.5603             78100.0  \n",
      "20636       356.0       114.0         2.5568             77100.0  \n",
      "20637      1007.0       433.0         1.7000             92300.0  \n",
      "20638       741.0       349.0         1.8672             84700.0  \n",
      "20639      1387.0       530.0         2.3886             89400.0  \n",
      "\n",
      "[20640 rows x 9 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "longitude               0\n",
       "latitude                0\n",
       "housing_median_age      0\n",
       "total_rooms             0\n",
       "total_bedrooms        207\n",
       "population              0\n",
       "households              0\n",
       "median_income           0\n",
       "median_house_value      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#elimino columna \"ocean_proximity\" porque no se usa:\n",
    "df.drop(\"ocean_proximity\", axis=1, inplace=True)\n",
    "\n",
    "# cuento cuantos valores faltantes:\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f7b9e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude             0\n",
       "latitude              0\n",
       "housing_median_age    0\n",
       "total_rooms           0\n",
       "total_bedrooms        0\n",
       "population            0\n",
       "households            0\n",
       "median_income         0\n",
       "median_house_value    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#elimino filas c valores faltantes\n",
    "df.dropna(inplace=True)\n",
    "#verifico:\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c90d7bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% separa atributos y clases\n",
    "X = np.array(df.iloc[:,:-1])  # recupera todas las columnas salvo la ultima\n",
    "Y = np.array(df.iloc[:,-1])    # recupera solo la ultima columna (valor a predecir)\n",
    "\n",
    "#normalizo con StandardScaler (usando media y desvio)\n",
    "# Escala los valores entre 0 y 1\n",
    "min_max_scaler = preprocessing.StandardScaler()\n",
    "X_train = min_max_scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d5937b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645/645 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13880\\2924651752.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Calcular R^2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mr2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"El valor de R^2 es: {r2}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\p37env\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36mr2_score\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    788\u001b[0m     \"\"\"\n\u001b[0;32m    789\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[1;32m--> 790\u001b[1;33m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    791\u001b[0m     )\n\u001b[0;32m    792\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\p37env\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\p37env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"allow-nan\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\p37env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    114\u001b[0m             raise ValueError(\n\u001b[0;32m    115\u001b[0m                 msg_err.format(\n\u001b[1;32m--> 116\u001b[1;33m                     \u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m                 )\n\u001b[0;32m    118\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Supongamos que Y_test son tus valores reales y Y_pred son predicciones del modelo\n",
    "Y_pred = model.predict(X_train)  # Predicciones del modelo\n",
    "\n",
    "# Calcular R^2\n",
    "r2 = r2_score(Y, Y_pred)\n",
    "\n",
    "print(f\"El valor de R^2 es: {r2}\")\n",
    "\n",
    "# Comprobar si es mayor a 0.9\n",
    "if r2 > 0.9:\n",
    "    print(\"El modelo tiene un buen ajuste (R^2 > 0.9)\")\n",
    "else:\n",
    "    print(\"El modelo no tiene un buen ajuste (R^2 <= 0.9)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e1bdf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5616e9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
