{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61d85b3a-61ad-424b-b84e-cae1411c1930",
   "metadata": {},
   "source": [
    "## EJERCICIO 3 - PRACTICA 4\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dee7ff02-a6e5-4e72-bbc3-24f9e3bf8fc3",
   "metadata": {},
   "source": [
    "El archivo Vinos.csv tiene información referida a 13 características químicas y/o visuales de varias muestras \n",
    "de vinos pertenecientes a 3 clases distintas\n",
    "#separar un grupo de datos, que el modelo no va a ver ?\n",
    "#DATASET --> se divide en entrenamiento y testeo\n",
    "# no se normaliza, pero se usa el one hot encoder*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f600909-5b31-4382-aaab-32b86bfabf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8661dd5e-30a9-4ae6-ad83-d50c8cccc266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuración para notebook con instalación LOCAL\n",
    "FUENTES_DIR = '../Fuentes' # carpeta donde se encuentran archivos .py auxiliares\n",
    "DATOS_DIR   = '../Datos/'  # carpeta donde se encuentran los datasets\n",
    "\n",
    "# agrega ruta de busqueda donde tenemos archivos .py\n",
    "import sys\n",
    "sys.path.append(FUENTES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6096c08a-2f41-4fa0-9609-da1419f54e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
      "0        1    14.23        1.71  2.43               15.6        127   \n",
      "1        1    13.20        1.78  2.14               11.2        100   \n",
      "2        1    13.16        2.36  2.67               18.6        101   \n",
      "3        1    14.37        1.95  2.50               16.8        113   \n",
      "4        1    13.24        2.59  2.87               21.0        118   \n",
      "..     ...      ...         ...   ...                ...        ...   \n",
      "173      3    13.71        5.65  2.45               20.5         95   \n",
      "174      3    13.40        3.91  2.48               23.0        102   \n",
      "175      3    13.27        4.28  2.26               20.0        120   \n",
      "176      3    13.17        2.59  2.37               20.0        120   \n",
      "177      3    14.13        4.10  2.74               24.5         96   \n",
      "\n",
      "     Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
      "0             2.80        3.06                  0.28             2.29   \n",
      "1             2.65        2.76                  0.26             1.28   \n",
      "2             2.80        3.24                  0.30             2.81   \n",
      "3             3.85        3.49                  0.24             2.18   \n",
      "4             2.80        2.69                  0.39             1.82   \n",
      "..             ...         ...                   ...              ...   \n",
      "173           1.68        0.61                  0.52             1.06   \n",
      "174           1.80        0.75                  0.43             1.41   \n",
      "175           1.59        0.69                  0.43             1.35   \n",
      "176           1.65        0.68                  0.53             1.46   \n",
      "177           2.05        0.76                  0.56             1.35   \n",
      "\n",
      "     Color intensity   Hue  OD280/OD315  Proline  \n",
      "0               5.64  1.04         3.92     1065  \n",
      "1               4.38  1.05         3.40     1050  \n",
      "2               5.68  1.03         3.17     1185  \n",
      "3               7.80  0.86         3.45     1480  \n",
      "4               4.32  1.04         2.93      735  \n",
      "..               ...   ...          ...      ...  \n",
      "173             7.70  0.64         1.74      740  \n",
      "174             7.30  0.70         1.56      750  \n",
      "175            10.20  0.59         1.56      835  \n",
      "176             9.30  0.60         1.62      840  \n",
      "177             9.20  0.61         1.60      560  \n",
      "\n",
      "[178 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd      # para trabajar con archivos de datos csv, excel, etc: https://pandas.pydata.org/docs/getting_started/tutorials.html\n",
    "import chardet           # para detectar la codificación de texto en archivos\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "nombre_archivo = DATOS_DIR + 'Vinos.csv' \n",
    "\n",
    "# recupera el archivo en un objeto dataframe de pandas utilizando la codificación detectada\n",
    "df = pd.read_csv(nombre_archivo, sep=';')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461950c8-8098-46af-8ae0-5e8f5d199d63",
   "metadata": {},
   "source": [
    "### Utilice el 80% de los ejemplos del archivo Vinos.csv para entrenar un multiperceptrón que sea capaz de distinguir entre las 3 clases de vinos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5641bb6f-45c2-4630-94b8-093fc314de2e",
   "metadata": {},
   "source": [
    "### Tengo que dividir el dataset en 2: El 80% para entrenamiento, y otro 20% para testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f4f0579-ca2f-4ea7-8785-407a4e43753e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las clases del dataset son : [1 2 3]\n",
      "[[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]]\n",
      "\n",
      "Datos de Entrenamiento: 142   Datos de Testeo: 36\n"
     ]
    }
   ],
   "source": [
    "# %% separa atributos y clases\n",
    "X_raw = np.array(df.iloc[:,1:])  # recupera todas las columnas salvo la primera (es la clase)\n",
    "Y_raw = np.array(df.iloc[:,0])    # recupera solo la primer columna (es la clase)\n",
    "\n",
    "# Binarizador para convertir el nombre de la clase en one hot encoding\n",
    "binarizer = preprocessing.LabelBinarizer()\n",
    "\n",
    "# Binariza cada clase como una combinación de un 1 y 0s\n",
    "Y_raw = binarizer.fit_transform(Y_raw)\n",
    "# Y_raw==pd.get_dummies(df[' Balance']).to_numpy() # forma alternativa para codificar\n",
    "\n",
    "print('Las clases del dataset son :', binarizer.classes_)\n",
    "print(Y_raw)\n",
    "# Escala los atributos de los ejemplo\n",
    "scaler = preprocessing.StandardScaler()\n",
    "#scaler = preprocessing.MinMaxScaler()\n",
    "X_raw  = scaler.fit_transform( X_raw )\n",
    "\n",
    "# %% Separa ejemplos para enternamiento y testeo:\n",
    "TEST_SIZE = 0.20 # proporcion entre testeo entre entrenamiento y testeo (utiliza 20% de los datos para testeo y el otro 80% de los datos para entrenamiento)\n",
    "# X_test e Y_test --> datos de testeo (x atributos, y valores a predecir) --> 20% del dataset\n",
    "# X_train e Y_train --> datos de entrenamiento --> 80% del dataset\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X_raw, Y_raw, test_size=TEST_SIZE)#, random_state=42)\n",
    "\n",
    "print('\\nDatos de Entrenamiento: %d   Datos de Testeo: %d' % (len(Y_train), len(Y_test) ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4a83752d-155b-4de5-b86d-695355fef490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efectividad:  98.59%\n",
      "      Score:   0.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\W10\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "FunH = 'tanh'   # identity logistic tanh relu\n",
    "ocultas = (8)\n",
    "\n",
    "alfa = 0.005\n",
    "CotaError = 1.0e-5\n",
    "MAX_ITE = 2500\n",
    "\n",
    "modelo = MLPClassifier(max_iter=MAX_ITE, hidden_layer_sizes=ocultas, alpha=alfa,\n",
    "                       solver='sgd', activation=FunH, tol=CotaError,\n",
    "                       verbose=False).fit(X_train, Y_train)\n",
    "\n",
    "modelo.out_activation_ = 'softmax'\n",
    "\n",
    "#  ########### Medición del entrenamiento ######################\n",
    "# entrenamiento con X_train e Y_train (80% del dataset)\n",
    "Y_pred = modelo.predict(X_train)\n",
    "score = modelo.score(X_train, Y_train)\n",
    "\n",
    "# \"invierte\" la transformacion binaria para obtener los nombres de las clases\n",
    "Y_it = binarizer.inverse_transform(Y_train)\n",
    "Y_pred_it = binarizer.inverse_transform(Y_pred)\n",
    "\n",
    "# calculo manual del accuracy\n",
    "print('Efectividad: %6.2f%%' % (100*(Y_pred_it == Y_it).sum()/len(Y_it)) )\n",
    "print('      Score: %6.2f%%' % (score) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dedfab-1e82-404b-a5ef-ac1578cde540",
   "metadata": {},
   "source": [
    "###  Observe la tasa de acierto obtenida sobre el 20% restante"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b59afc-60c1-4592-8a0c-a723151c7de7",
   "metadata": {},
   "source": [
    "### Utilizo para testear el 20% de los ejemplos del dataset, y analizo metricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "297da0e0-de8e-4e9b-9114-11132c55e797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efectividad:  91.67%\n",
      "      Score:   0.92%\n"
     ]
    }
   ],
   "source": [
    "#  ########### Medición del testeo ######################\n",
    "# utilizo X_test e Y_test --> el 20% del dataset separado para testear\n",
    "Y_pred = modelo.predict(X_test)\n",
    "score = modelo.score(X_test, Y_test)\n",
    "\n",
    "# \"invierte\" la transformacion binaria para obtener los nombres de las clases\n",
    "Y_it = binarizer.inverse_transform(Y_test)\n",
    "Y_pred_it = binarizer.inverse_transform(Y_pred)\n",
    "\n",
    "# calculo manual del accuracy\n",
    "print('Efectividad: %6.2f%%' % (100*(Y_pred_it == Y_it).sum()/len(Y_it)) )\n",
    "print('      Score: %6.2f%%' % (score) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7747d466-c1be-4241-80bb-ead9bbf439b9",
   "metadata": {},
   "source": [
    "### Impresion de métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f0deb3d2-bd90-4f55-9c80-9904f656d68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Matriz de Confusión:\n",
      "[[10  0  0]\n",
      " [ 1  8  1]\n",
      " [ 0  1 15]] \n",
      "\n",
      "Resultado de la clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      1.00      0.95        10\n",
      "           2       0.89      0.80      0.84        10\n",
      "           3       0.94      0.94      0.94        16\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.91      0.91      0.91        36\n",
      "weighted avg       0.92      0.92      0.92        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "# Y_pred --> vector con predicciones hechas por la red\n",
    "# Y_test --> vector con valores reales\n",
    "\n",
    "#convierto las predicciones y las etiquetas verdaderas de formato one-hot a etiquetas numéricas (escalar) porque confusion_matrix no soporta o-h-encoding\n",
    "Y_test_labels = binarizer.inverse_transform(Y_test)\n",
    "Y_pred_labels = binarizer.inverse_transform(Y_pred)\n",
    "\n",
    "confusion = confusion_matrix(Y_test_labels, Y_pred_labels)\n",
    "print('\\n Matriz de Confusión:')\n",
    "print(confusion, '\\n')\n",
    "\n",
    "################################ calcula todas las métricas juntas #################################\n",
    "report = metrics.classification_report(Y_test_labels, Y_pred_labels)\n",
    "print('Resultado de la clasificación:\\n%s' % report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b9e124-e4c5-4555-875f-4051ab1088f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
