{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aac65946-e7e8-41bb-81ee-0d59ddc5eb51",
   "metadata": {},
   "source": [
    "## EJERCICIO 10 - PRACTICA 3"
   ]
  },
  {
   "cell_type": "raw",
   "id": "132e8732-ba8c-4dde-8064-1c93f081ac0e",
   "metadata": {},
   "source": [
    "Se ha realizado un análisis químico a tres tipos distintos de vinos producidos en una misma región de Italia\n",
    "El archivo Vinos.csv permite observar los resultados de este análisis. Cada fila representa una muestra \n",
    "distinta y está formada, en primer lugar, por el número del tipo al cual pertenece el vino analizado seguido \n",
    "por los 13 atributos que lo caracterizan.\n",
    "\n",
    "Por ejemplo, la siguiente fila:\n",
    "2, 12.29, 3.17, 2.21, 18, 88, 2.85, 2.99, 0.45, 2.81, 2.3, 1.42, 2.83, 406\n",
    "es el resultado del análisis de un vino correspondiente al tipo 2 (1er. valor de la fila) seguido por 13 valores \n",
    "separados por comas que indican los niveles de las mediciones realizadas a dicho vino. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9204a1-1437-4e92-b8fe-5da928326a07",
   "metadata": {},
   "source": [
    "### Importo librerias\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ee5d2671-213e-4e7d-bd7c-81b742597de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ColabNotebook = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if ColabNotebook:\n",
    "    # monta G-drive en entorno COLAB\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')\n",
    "\n",
    "    # carpeta donde se encuentran archivos .py auxiliares\n",
    "    FUENTES_DIR = '/content/drive/MyDrive/Colab Notebooks/FUENTES/'\n",
    "    DATOS_DIR = '/content/drive/MyDrive/Colab Notebooks/DATOS/'      # carpeta donde se encuentran los datasets\n",
    "else:\n",
    "    # configuración para notebook con instalación LOCAL\n",
    "    FUENTES_DIR = '../Fuentes'         # carpeta donde se encuentran archivos .py auxiliares\n",
    "    DATOS_DIR   = '../Datos/' # carpeta donde se encuentran los datasets\n",
    "\n",
    "# agrega ruta de busqueda donde tenemos archivos .py\n",
    "import sys\n",
    "sys.path.append(FUENTES_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb86964-d145-4a2d-abef-255abc3fd21e",
   "metadata": {},
   "source": [
    "### Leo dataframe\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5b865e1c-d1f4-4cf2-b623-f3d0753a9b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "0      1    14.23        1.71  2.43               15.6        127   \n",
       "1      1    13.20        1.78  2.14               11.2        100   \n",
       "2      1    13.16        2.36  2.67               18.6        101   \n",
       "3      1    14.37        1.95  2.50               16.8        113   \n",
       "4      1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color intensity   Hue  OD280/OD315  Proline  \n",
       "0             5.64  1.04         3.92     1065  \n",
       "1             4.38  1.05         3.40     1050  \n",
       "2             5.68  1.03         3.17     1185  \n",
       "3             7.80  0.86         3.45     1480  \n",
       "4             4.32  1.04         2.93      735  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd      # para trabajar con archivos de datos csv, excel, etc: https://pandas.pydata.org/docs/getting_started/tutorials.html\n",
    "import chardet           # para detectar la codificación de texto en archivos\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# importa neurona lineal de Laura en la carpeta Colab definida con FUENTES_DIR\n",
    "from ClassNeuronaLineal import NeuronaLineal\n",
    "\n",
    "nombre_archivo = DATOS_DIR + 'Vinos.csv' # archivo de hojas\n",
    "\n",
    "#-- detectando la codificación de caracteres usada ----\n",
    "with open(nombre_archivo, 'rb') as f:\n",
    "    result = chardet.detect(f.read())  # or readline if the file is large\n",
    "\n",
    "# recupera el archivo en un objeto dataframe de pandas utilizando la codificación detectada\n",
    "df = pd.read_csv(nombre_archivo, delimiter=';' , nrows=None) # uso ';' por como esta organizado el dataframe\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "67067665-df5d-480e-ae9a-1cc3a89bc87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
      "0      1    14.23        1.71  2.43               15.6        127   \n",
      "1      1    13.20        1.78  2.14               11.2        100   \n",
      "2      1    13.16        2.36  2.67               18.6        101   \n",
      "3      1    14.37        1.95  2.50               16.8        113   \n",
      "4      1    13.24        2.59  2.87               21.0        118   \n",
      "\n",
      "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
      "0           2.80        3.06                  0.28             2.29   \n",
      "1           2.65        2.76                  0.26             1.28   \n",
      "2           2.80        3.24                  0.30             2.81   \n",
      "3           3.85        3.49                  0.24             2.18   \n",
      "4           2.80        2.69                  0.39             1.82   \n",
      "\n",
      "   Color intensity   Hue  OD280/OD315  Proline  \n",
      "0             5.64  1.04         3.92     1065  \n",
      "1             4.38  1.05         3.40     1050  \n",
      "2             5.68  1.03         3.17     1185  \n",
      "3             7.80  0.86         3.45     1480  \n",
      "4             4.32  1.04         2.93      735  \n",
      "     Class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
      "173      3    13.71        5.65  2.45               20.5         95   \n",
      "174      3    13.40        3.91  2.48               23.0        102   \n",
      "175      3    13.27        4.28  2.26               20.0        120   \n",
      "176      3    13.17        2.59  2.37               20.0        120   \n",
      "177      3    14.13        4.10  2.74               24.5         96   \n",
      "\n",
      "     Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
      "173           1.68        0.61                  0.52             1.06   \n",
      "174           1.80        0.75                  0.43             1.41   \n",
      "175           1.59        0.69                  0.43             1.35   \n",
      "176           1.65        0.68                  0.53             1.46   \n",
      "177           2.05        0.76                  0.56             1.35   \n",
      "\n",
      "     Color intensity   Hue  OD280/OD315  Proline  \n",
      "173              7.7  0.64         1.74      740  \n",
      "174              7.3  0.70         1.56      750  \n",
      "175             10.2  0.59         1.56      835  \n",
      "176              9.3  0.60         1.62      840  \n",
      "177              9.2  0.61         1.60      560  \n"
     ]
    }
   ],
   "source": [
    "#verifico las primeras y ultimas filas (solo para ver si se leyó bien el csv)\n",
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60034aee-affd-4c48-a014-dc35d0bcd888",
   "metadata": {},
   "source": [
    "###  Se quiere entrenar una red neuronal formada por una única neurona para clasificar los vinos de Tipo 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4379b251-18b4-462a-b742-5a345a33539e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analizo cuantas clases tiene 'Clase'\n",
    "df['Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e753ae26-2a96-45c4-b87c-ab1c1acb77b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class_1</th>\n",
       "      <th>Class_2</th>\n",
       "      <th>Class_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class_1  Class_2  Class_3\n",
       "0        1        0        0\n",
       "1        1        0        0\n",
       "2        1        0        0\n",
       "3        1        0        0\n",
       "4        1        0        0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Como se quiere clasificar los vinos de tipo 1, genero una columna binaria por cada tipo que haya\n",
    "\n",
    "df_one_hot = pd.get_dummies(df['Class'], prefix='Class').astype(int) #genera una nueva columna binaria por cada tipo de clase\n",
    "df_one_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8282357a-71b6-448d-967b-0ad0779899f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315</th>\n",
       "      <th>Proline</th>\n",
       "      <th>Class_1</th>\n",
       "      <th>Class_2</th>\n",
       "      <th>Class_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  Total phenols  \\\n",
       "0    14.23        1.71  2.43               15.6        127           2.80   \n",
       "1    13.20        1.78  2.14               11.2        100           2.65   \n",
       "2    13.16        2.36  2.67               18.6        101           2.80   \n",
       "3    14.37        1.95  2.50               16.8        113           3.85   \n",
       "4    13.24        2.59  2.87               21.0        118           2.80   \n",
       "\n",
       "   Flavanoids  Nonflavanoid phenols  Proanthocyanins  Color intensity   Hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   OD280/OD315  Proline  Class_1  Class_2  Class_3  \n",
       "0         3.92     1065        1        0        0  \n",
       "1         3.40     1050        1        0        0  \n",
       "2         3.17     1185        1        0        0  \n",
       "3         3.45     1480        1        0        0  \n",
       "4         2.93      735        1        0        0  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#agrego las columnas binarias generadas al datframe, y elimino la columna \"Class\"\n",
    "df = pd.concat([df,df_one_hot], axis=1)\n",
    "df = df.drop('Class', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6a8d9d-5131-4c1e-a2d8-2893091a487f",
   "metadata": {},
   "source": [
    "### Genero los arreglos X e Y (entradas y valores a predecir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3bd650-c68a-4686-9942-3cfbc5bac4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['Class_2']\n",
    "X = df.drop(columns=['Clss_2']) # datos de entrada\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8923ef8f-5dca-4955-b1d1-2fc976771bdf",
   "metadata": {},
   "source": [
    "### Normalizacion de datos de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39b72dd-5c64-4797-b1fa-edc17aadc28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4b2eb157-d2d1-4410-a9cc-d725f1b6e471",
   "metadata": {},
   "source": [
    "Realice 30 ejecuciones independientes utilizando el 50%, 60%, 70%, 80% y 90% de los ejemplos como \n",
    "entrenamiento y el resto como testeo. Para cada porcentaje, indique la cantidad promedio de ejemplos \n",
    "correctamente clasificados en entrenamiento y en testeo. Calcule también el promedio y el desvío de la \n",
    "cantidad de iteraciones realizadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f185f23-a547-4bc3-bacf-d1b3cf38fb5f",
   "metadata": {},
   "source": [
    "### Entrenamiento usando el 50%, 60%, 70%, 80%, 90% de los ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "a7b7672d-f7c3-4904-b894-1ecc9c25e1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f06ec270-1afb-4177-ba3b-5c52d130611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion que divide datos, entrena el modelo y evalua la presicon del mismo:\n",
    "def train_and_evaluate(X, y, test_size):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=None)\n",
    "    model = LogisticRegression(max_iter=30)  # Puedes ajustar max_iter si es necesario\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicciones en entrenamiento y prueba\n",
    "    train_predictions = model.predict(X_train)\n",
    "    test_predictions = model.predict(X_test)\n",
    "    \n",
    "    # Conteo de ejemplos correctamente clasificados (para luego sacar promedio y desv)\n",
    "    correct_train = np.sum(train_predictions == y_train)\n",
    "    correct_test = np.sum(test_predictions == y_test)\n",
    "    \n",
    "    # Precisión\n",
    "    accuracy = accuracy_score(y_test, test_predictions)\n",
    "    \n",
    "    return correct_train, correct_test, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "3d6e0f31-9288-4e0e-b561-24ac69aa7bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de prueba 50%:\n",
      "Promedio de ejemplos correctamente clasificados en entrenamiento: 105.0\n",
      "Desviación estándar de ejemplos correctamente clasificados en entrenamiento: 0.0\n",
      "Promedio de ejemplos correctamente clasificados en testeo: 104.86666666666666\n",
      "Desviación estándar de ejemplos correctamente clasificados en testeo: 0.42687494916218993\n",
      "Promedio de precisión: 0.9987301587301587\n",
      "Desviación estándar de precisión: 0.004065475706306572\n",
      "______________________________________________________________________________________________\n",
      "Tamaño de prueba 60%:\n",
      "Promedio de ejemplos correctamente clasificados en entrenamiento: 84.0\n",
      "Desviación estándar de ejemplos correctamente clasificados en entrenamiento: 0.0\n",
      "Promedio de ejemplos correctamente clasificados en testeo: 125.66666666666667\n",
      "Desviación estándar de ejemplos correctamente clasificados en testeo: 0.5962847939999438\n",
      "Promedio de precisión: 0.9973544973544974\n",
      "Desviación estándar de precisión: 0.004732418999999559\n",
      "______________________________________________________________________________________________\n",
      "Tamaño de prueba 70%:\n",
      "Promedio de ejemplos correctamente clasificados en entrenamiento: 63.0\n",
      "Desviación estándar de ejemplos correctamente clasificados en entrenamiento: 0.0\n",
      "Promedio de ejemplos correctamente clasificados en testeo: 146.16666666666666\n",
      "Desviación estándar de ejemplos correctamente clasificados en testeo: 0.9339283817414601\n",
      "Promedio de precisión: 0.9943310657596371\n",
      "Desviación estándar de precisión: 0.006353254297560959\n",
      "______________________________________________________________________________________________\n",
      "Tamaño de prueba 80%:\n",
      "Promedio de ejemplos correctamente clasificados en entrenamiento: 42.0\n",
      "Desviación estándar de ejemplos correctamente clasificados en entrenamiento: 0.0\n",
      "Promedio de ejemplos correctamente clasificados en testeo: 167.16666666666666\n",
      "Desviación estándar de ejemplos correctamente clasificados en testeo: 0.8975274678557507\n",
      "Promedio de precisión: 0.9950396825396826\n",
      "Desviación estándar de precisión: 0.005342425403903259\n",
      "______________________________________________________________________________________________\n",
      "Tamaño de prueba 90%:\n",
      "Promedio de ejemplos correctamente clasificados en entrenamiento: 21.0\n",
      "Desviación estándar de ejemplos correctamente clasificados en entrenamiento: 0.0\n",
      "Promedio de ejemplos correctamente clasificados en testeo: 186.2\n",
      "Desviación estándar de ejemplos correctamente clasificados en testeo: 2.8913664589601917\n",
      "Promedio de precisión: 0.9851851851851854\n",
      "Desviación estándar de precisión: 0.015298235232593617\n",
      "______________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)  # Para reproducibilidad si es necesario\n",
    "num_executions = 30\n",
    "test_sizes = [0.50, 0.60, 0.70, 0.80, 0.90]  # Proporciones de tamaño del conjunto de prueba\n",
    "results = {'50%': {'train': [], 'test': [], 'accuracy': []},\n",
    "            '60%': {'train': [], 'test': [], 'accuracy': []},\n",
    "           '70%': {'train': [], 'test': [], 'accuracy': []},\n",
    "           '80%': {'train': [], 'test': [], 'accuracy': []}, \n",
    "           '90%': {'train': [], 'test': [], 'accuracy': []} }\n",
    "\n",
    "# Ejecutar el proceso de entrenamiento y prueba\n",
    "for test_size in test_sizes:\n",
    "    for _ in range(num_executions):\n",
    "        correct_train, correct_test, accuracy = train_and_evaluate(X, Y, test_size)\n",
    "        results[f'{int(test_size * 100)}%']['train'].append(correct_train)\n",
    "        results[f'{int(test_size * 100)}%']['test'].append(correct_test)\n",
    "        results[f'{int(test_size * 100)}%']['accuracy'].append(accuracy)\n",
    "\n",
    "# Mostrar los resultados\n",
    "for size, metrics in results.items():\n",
    "    avg_train_correct = np.mean(metrics['train'])\n",
    "    avg_test_correct = np.mean(metrics['test'])\n",
    "    std_train_correct = np.std(metrics['train'])\n",
    "    std_test_correct = np.std(metrics['test'])\n",
    "    avg_accuracy = np.mean(metrics['accuracy'])\n",
    "    std_accuracy = np.std(metrics['accuracy'])\n",
    "    \n",
    "    print(f'Tamaño de prueba {size}:')\n",
    "    print(f'Promedio de ejemplos correctamente clasificados en entrenamiento: {avg_train_correct}')\n",
    "    print(f'Desviación estándar de ejemplos correctamente clasificados en entrenamiento: {std_train_correct}')\n",
    "    print(f'Promedio de ejemplos correctamente clasificados en testeo: {avg_test_correct}')\n",
    "    print(f'Desviación estándar de ejemplos correctamente clasificados en testeo: {std_test_correct}')\n",
    "    print(f'Promedio de precisión: {avg_accuracy}')\n",
    "    print(f'Desviación estándar de precisión: {std_accuracy}')\n",
    "    print(f'______________________________________________________________________________________________')\n",
    "\n",
    "# Desv estandar: indica cuánto varían las precisiones obtenidas en cada ejecución respecto al promedio de todas las ejecuciones\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c2b5d46-f3c2-469c-aaf8-01ae9a8dd69b",
   "metadata": {},
   "source": [
    "*Promedio de Ejemplos Correctamente Clasificados en Entrenamiento y Testeo: Esto se refiere a calcular el promedio del número de ejemplos que el modelo clasifica correctamente en los conjuntos de entrenamiento y de prueba a lo largo de las múltiples ejecuciones."
   ]
  },
  {
   "cell_type": "raw",
   "id": "76f6ae01-5298-4706-bf2b-c61c2e3f2de5",
   "metadata": {},
   "source": [
    "*Promedio y Desvío de la Cantidad de Iteraciones Realizadas: calcular el promedio y la desviación estándar del número de iteraciones que se realizan en el entrenamiento del modelo en cada ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1a77b681-23a1-44ca-a9a8-f92c8ed6dd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad629833-cdab-461c-8d06-62d06da110c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no se como seguir usando sigmoid y todo loq ue pide a) b) c)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "46690ff2-31f2-4e8c-aba3-08b5cd899662",
   "metadata": {},
   "source": [
    "Utilice un máximo de 400 iteraciones y velocidades de aprendizaje 0.1, 0.2 y 0.3.\n",
    "Analice los resultados obtenidos utilizando:\n",
    "i. Función de activación ‘sigmoid’ y función de costo ‘ECM’ (error cuadrático medio)\n",
    "ii. Función de activación ‘sigmoid’ y función de costo ‘EC_binaria’ (entropía cruzada binaria)\n",
    "iii. Función de activación ‘tanh’ y función de costo ‘ECM’ (error cuadrático medio)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
