{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61d85b3a-61ad-424b-b84e-cae1411c1930",
   "metadata": {},
   "source": [
    "## EJERCICIO 3 - PRACTICA 4\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dee7ff02-a6e5-4e72-bbc3-24f9e3bf8fc3",
   "metadata": {},
   "source": [
    "El archivo Vinos.csv tiene información referida a 13 características químicas y/o visuales de varias muestras \n",
    "de vinos pertenecientes a 3 clases distintas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f600909-5b31-4382-aaab-32b86bfabf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8661dd5e-30a9-4ae6-ad83-d50c8cccc266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuración para notebook con instalación LOCAL\n",
    "FUENTES_DIR = '../Fuentes' # carpeta donde se encuentran archivos .py auxiliares\n",
    "DATOS_DIR   = '../Datos/'  # carpeta donde se encuentran los datasets\n",
    "\n",
    "# agrega ruta de busqueda donde tenemos archivos .py\n",
    "import sys\n",
    "sys.path.append(FUENTES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6096c08a-2f41-4fa0-9609-da1419f54e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
      "0        1    14.23        1.71  2.43               15.6        127   \n",
      "1        1    13.20        1.78  2.14               11.2        100   \n",
      "2        1    13.16        2.36  2.67               18.6        101   \n",
      "3        1    14.37        1.95  2.50               16.8        113   \n",
      "4        1    13.24        2.59  2.87               21.0        118   \n",
      "..     ...      ...         ...   ...                ...        ...   \n",
      "173      3    13.71        5.65  2.45               20.5         95   \n",
      "174      3    13.40        3.91  2.48               23.0        102   \n",
      "175      3    13.27        4.28  2.26               20.0        120   \n",
      "176      3    13.17        2.59  2.37               20.0        120   \n",
      "177      3    14.13        4.10  2.74               24.5         96   \n",
      "\n",
      "     Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
      "0             2.80        3.06                  0.28             2.29   \n",
      "1             2.65        2.76                  0.26             1.28   \n",
      "2             2.80        3.24                  0.30             2.81   \n",
      "3             3.85        3.49                  0.24             2.18   \n",
      "4             2.80        2.69                  0.39             1.82   \n",
      "..             ...         ...                   ...              ...   \n",
      "173           1.68        0.61                  0.52             1.06   \n",
      "174           1.80        0.75                  0.43             1.41   \n",
      "175           1.59        0.69                  0.43             1.35   \n",
      "176           1.65        0.68                  0.53             1.46   \n",
      "177           2.05        0.76                  0.56             1.35   \n",
      "\n",
      "     Color intensity   Hue  OD280/OD315  Proline  \n",
      "0               5.64  1.04         3.92     1065  \n",
      "1               4.38  1.05         3.40     1050  \n",
      "2               5.68  1.03         3.17     1185  \n",
      "3               7.80  0.86         3.45     1480  \n",
      "4               4.32  1.04         2.93      735  \n",
      "..               ...   ...          ...      ...  \n",
      "173             7.70  0.64         1.74      740  \n",
      "174             7.30  0.70         1.56      750  \n",
      "175            10.20  0.59         1.56      835  \n",
      "176             9.30  0.60         1.62      840  \n",
      "177             9.20  0.61         1.60      560  \n",
      "\n",
      "[178 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd      # para trabajar con archivos de datos csv, excel, etc: https://pandas.pydata.org/docs/getting_started/tutorials.html\n",
    "import chardet           # para detectar la codificación de texto en archivos\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "nombre_archivo = DATOS_DIR + 'Vinos.csv' \n",
    "\n",
    "# recupera el archivo en un objeto dataframe de pandas utilizando la codificación detectada\n",
    "df = pd.read_csv(nombre_archivo, sep=';')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f4f0579-ca2f-4ea7-8785-407a4e43753e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las clases del dataset son : [1 2 3]\n",
      "[[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]]\n",
      "\n",
      "Datos de Entrenamiento: 35   Datos de Testeo: 143\n"
     ]
    }
   ],
   "source": [
    "# %% separa atributos y clases\n",
    "X_raw = np.array(df.iloc[:,1:])  # recupera todas las columnas salvo la primera (es la clase)\n",
    "Y_raw = np.array(df.iloc[:,0])    # recupera solo la primer columna (es la clase)\n",
    "\n",
    "# Binarizador para convertir el nombre de la clase en one hot encoding\n",
    "binarizer = preprocessing.LabelBinarizer()\n",
    "\n",
    "# Binariza cada clase como una combinación de un 1 y 0s\n",
    "Y_raw = binarizer.fit_transform(Y_raw)\n",
    "# Y_raw==pd.get_dummies(df[' Balance']).to_numpy() # forma alternativa para codificar\n",
    "\n",
    "print('Las clases del dataset son :', binarizer.classes_)\n",
    "print(Y_raw)\n",
    "# Escala los atributos de los ejemplo\n",
    "scaler = preprocessing.StandardScaler()\n",
    "#scaler = preprocessing.MinMaxScaler()\n",
    "X_raw  = scaler.fit_transform( X_raw )\n",
    "\n",
    "# %% Separa ejemplos para enternamiento y testeo\n",
    "TEST_SIZE = 0.8 # proporcion entre testeo entre entrenamiento y testeo (utiliza 80% de los datos)\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X_raw, Y_raw, test_size=TEST_SIZE)#, random_state=42)\n",
    "\n",
    "print('\\nDatos de Entrenamiento: %d   Datos de Testeo: %d' % (len(Y_train), len(Y_test) ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a83752d-155b-4de5-b86d-695355fef490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efectividad: 100.00%\n",
      "      Score:   1.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\W10\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "FunH = 'tanh'   # identity logistic tanh relu\n",
    "ocultas = (8)\n",
    "\n",
    "alfa = 0.005\n",
    "CotaError = 1.0e-5\n",
    "MAX_ITE = 2500\n",
    "\n",
    "modelo = MLPClassifier(max_iter=MAX_ITE, hidden_layer_sizes=ocultas, alpha=alfa,\n",
    "                       solver='sgd', activation=FunH, tol=CotaError,\n",
    "                       verbose=False).fit(X_train, Y_train)\n",
    "\n",
    "modelo.out_activation_ = 'softmax'\n",
    "\n",
    "#  ########### Medición del entrenamiento ######################\n",
    "Y_pred = modelo.predict(X_train)\n",
    "score = modelo.score(X_train, Y_train)\n",
    "\n",
    "# \"invierte\" la transformacion binaria para obtener los nombres de las clases\n",
    "Y_it = binarizer.inverse_transform(Y_train)\n",
    "Y_pred_it = binarizer.inverse_transform(Y_pred)\n",
    "\n",
    "# calculo manual del accuracy\n",
    "print('Efectividad: %6.2f%%' % (100*(Y_pred_it == Y_it).sum()/len(Y_it)) )\n",
    "print('      Score: %6.2f%%' % (score) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "297da0e0-de8e-4e9b-9114-11132c55e797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efectividad:  96.50%\n",
      "      Score:   0.97%\n"
     ]
    }
   ],
   "source": [
    "#  ########### Medición del testeo ######################\n",
    "Y_pred = modelo.predict(X_test)\n",
    "score = modelo.score(X_test, Y_test)\n",
    "\n",
    "# \"invierte\" la transformacion binaria para obtener los nombres de las clases\n",
    "Y_it = binarizer.inverse_transform(Y_test)\n",
    "Y_pred_it = binarizer.inverse_transform(Y_pred)\n",
    "\n",
    "# calculo manual del accuracy\n",
    "print('Efectividad: %6.2f%%' % (100*(Y_pred_it == Y_it).sum()/len(Y_it)) )\n",
    "print('      Score: %6.2f%%' % (score) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387e0c97-2d3b-471c-bc9e-28651733d0e0",
   "metadata": {},
   "source": [
    "# como  calculo  la tasa de acierto obtenida sobre el 20% restante. ***********"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15687e0-ffd7-487c-8c44-061a9b3803fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
