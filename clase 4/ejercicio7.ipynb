{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a457ebb3-055d-49d5-946e-1122faca3a90",
   "metadata": {},
   "source": [
    "## EJERCICIO 6 - PRACTICA 4"
   ]
  },
  {
   "cell_type": "raw",
   "id": "16732c72-8db4-4e02-bcc9-2f76ba6fb288",
   "metadata": {},
   "source": [
    "Los archivos Segment_Train.csv y Segment_Test.csv contienen información referida a regiones de 3x3 \n",
    "pixeles pertenecientes a 7 imágenes distintas.\n",
    "Cada imagen corresponde a uno de los siguientes tipos de superficie: ladrillo, cielo, follaje, cemento, ventana, camino y pasto."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b1377cbb-d213-4e60-a47b-cf026d140a2c",
   "metadata": {},
   "source": [
    "Cada región de 3x3 ha sido caracterizada por 19 atributos numéricos:\n",
    "1. region-centroid-col: la columna del pixel central de la región.\n",
    "2. region-centroid-row: la fila del pixel central de la región.\n",
    "3. region-pixel-count: el número de pixeles de la región = 9.\n",
    "4. short-line-density-5: el resultado de un algoritmo de extracción de líneas que cuenta la \n",
    "cantidad de líneas de bajo contraste que atraviesan la región.\n",
    "5. short-line-density-2: ídem anterior para líneas de alto contraste.\n",
    "6. vedge-mean: medida del contraste entre pixeles adyacentes. Este atributo contiene el valor \n",
    "promedio y el siguiente la desviación. Estas medidas sirven para detectar la presencia de un eje \n",
    "vertical.\n",
    "7. vegde-sd: (ver 6)\n",
    "8. hedge-mean: ídem 6 para eje horizontal. Contiene el valor medio y el siguiente la desviación. \n",
    "9. hedge-sd: (ver 8).\n",
    "10. intensity-mean: El promedio calculado sobre la región de la forma (R + G + B)/3\n",
    "11. rawred-mean: el promedio sobre la región de los valores R. \n",
    "12. rawblue-mean: el promedio sobre la región de los valores B.\n",
    "13. rawgreen-mean: el promedio sobre la región de los valores G.\n",
    "14. exred-mean: Medida de exceso de color rojo: (2R - (G + B))\n",
    "15. exblue-mean: Medida de exceso de color azul: (2B - (G + R))\n",
    "16. exgreen-mean: Medida de exceso de color verde: (2G - (R + B))\n",
    "17. value-mean: Transformación no lineal 3D de RGB.\n",
    "18. saturatoin-mean: (ver 17)\n",
    "19. hue-mean: ver 17)\n",
    "\n",
    "El atributo 20 corresponde al número de imagen de la cual fue extraída la región de 3x3. Sus valores son: 1 (ladrillo), 2 (cemento), 3(follaje), 4 (pasto), 5 (camino), 6 (cielo), 7 (ventana)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b2ea9e-d4c5-45c9-9e67-d96b1c9081fb",
   "metadata": {},
   "source": [
    "### Importo paquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39a6ef77-0108-4265-a3f5-a98b7ce203f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd      # para trabajar con archivos de datos csv, excel, etc: https://pandas.pydata.org/docs/getting_started/tutorials.html\n",
    "import chardet           # para detectar la codificación de texto en archivos\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing, model_selection\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8718212d-8e5b-4441-b179-c824df03db23",
   "metadata": {},
   "source": [
    "### Importo datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22831cc1-a56c-4e4b-a12c-572afa51a2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuración para notebook con instalación LOCAL\n",
    "FUENTES_DIR = '../Fuentes' # carpeta donde se encuentran archivos .py auxiliares\n",
    "DATOS_DIR   = '../Datos/'  # carpeta donde se encuentran los datasets\n",
    "\n",
    "# agrega ruta de busqueda donde tenemos archivos .py\n",
    "import sys\n",
    "sys.path.append(FUENTES_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd84629c-3901-46f7-8448-972dac1b0ce8",
   "metadata": {},
   "source": [
    "### Datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e251e9e6-6fc8-43fc-bee3-b80a68961185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        REGION-CENTROID-COL  REGION-CENTROID-ROW  REGION-PIXEL-COUNT  \\\n",
      "GRASS                 110.0                189.0                   9   \n",
      "GRASS                  86.0                187.0                   9   \n",
      "GRASS                 225.0                244.0                   9   \n",
      "GRASS                  47.0                232.0                   9   \n",
      "GRASS                  97.0                186.0                   9   \n",
      "...                     ...                  ...                 ...   \n",
      "CEMENT                 32.0                158.0                   9   \n",
      "CEMENT                  8.0                162.0                   9   \n",
      "CEMENT                128.0                161.0                   9   \n",
      "CEMENT                150.0                158.0                   9   \n",
      "CEMENT                124.0                162.0                   9   \n",
      "\n",
      "        SHORT-LINE-DENSITY-5  SHORT-LINE-DENSITY-2  VEDGE-MEAN  VEDGE-SD  \\\n",
      "GRASS               0.000000                   0.0    1.000000  0.666667   \n",
      "GRASS               0.000000                   0.0    1.111111  0.720082   \n",
      "GRASS               0.000000                   0.0    3.388889  2.195113   \n",
      "GRASS               0.000000                   0.0    1.277778  1.254621   \n",
      "GRASS               0.000000                   0.0    1.166667  0.691215   \n",
      "...                      ...                   ...         ...       ...   \n",
      "CEMENT              0.000000                   0.0    0.944445  0.862963   \n",
      "CEMENT              0.111111                   0.0    1.611111  2.062962   \n",
      "CEMENT              0.000000                   0.0    0.555555  0.251852   \n",
      "CEMENT              0.000000                   0.0    2.166667  1.633334   \n",
      "CEMENT              0.111111                   0.0    1.388889  1.129630   \n",
      "\n",
      "        HEDGE-MEAN  HEDGE-SD  INTENSITY-MEAN  RAWRED-MEAN  RAWBLUE-MEAN  \\\n",
      "GRASS     1.222222  1.186342       12.925926    10.888889      9.222222   \n",
      "GRASS     1.444444  0.750309       13.740741    11.666667     10.333334   \n",
      "GRASS     3.000000  1.520234       12.259259    10.333334      9.333334   \n",
      "GRASS     1.000000  0.894427       12.703704    11.000000      9.000000   \n",
      "GRASS     1.166667  1.005540       15.592592    13.888889     11.777778   \n",
      "...            ...       ...             ...          ...           ...   \n",
      "CEMENT    0.833333  0.611111        7.962963     6.333334     11.888889   \n",
      "CEMENT    0.333333  0.133333        8.370370     6.666666     12.000000   \n",
      "CEMENT    0.777778  0.162963        7.148148     5.555555     10.888889   \n",
      "CEMENT    1.388889  0.418518        8.444445     7.000000     12.222222   \n",
      "CEMENT    2.000000  0.888889       10.037037     8.000000     14.555555   \n",
      "\n",
      "        RAWGREEN-MEAN  EXRED-MEAN  EXBLUE-MEAN  EXGREEN-MEAN  VALUE-MEAN  \\\n",
      "GRASS       18.666668   -6.111111   -11.111111     17.222221   18.666668   \n",
      "GRASS       19.222221   -6.222222   -10.222222     16.444445   19.222221   \n",
      "GRASS       17.111110   -5.777778    -8.777778     14.555555   17.111110   \n",
      "GRASS       18.111110   -5.111111   -11.111111     16.222221   18.111110   \n",
      "GRASS       21.111110   -5.111111   -11.444445     16.555555   21.111110   \n",
      "...               ...         ...          ...           ...         ...   \n",
      "CEMENT       5.666666   -4.888889    11.777778     -6.888889   11.888889   \n",
      "CEMENT       6.444445   -5.111111    10.888889     -5.777778   12.000000   \n",
      "CEMENT       5.000000   -4.777778    11.222222     -6.444445   10.888889   \n",
      "CEMENT       6.111111   -4.333334    11.333333     -7.000000   12.222222   \n",
      "CEMENT       7.555555   -6.111111    13.555555     -7.444445   14.555555   \n",
      "\n",
      "        SATURATION-MEAN  HUE-MEAN  \n",
      "GRASS          0.508139  1.910864  \n",
      "GRASS          0.463329  1.941465  \n",
      "GRASS          0.480149  1.987902  \n",
      "GRASS          0.500966  1.875362  \n",
      "GRASS          0.442661  1.863654  \n",
      "...                 ...       ...  \n",
      "CEMENT         0.520578 -1.982834  \n",
      "CEMENT         0.484805 -2.044946  \n",
      "CEMENT         0.540918 -1.996307  \n",
      "CEMENT         0.503086 -1.943449  \n",
      "CEMENT         0.479931 -2.029312  \n",
      "\n",
      "[2100 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nombre_archivo = DATOS_DIR + 'Segment_Train.csv' \n",
    "\n",
    "#-- detectando la codificación de caracteres usada ----\n",
    "with open(nombre_archivo, 'rb') as f:\n",
    "    result = chardet.detect(f.read())  # or readline if the file is large\n",
    "\n",
    "# recupera el archivo en un objeto dataframe de pandas utilizando la codificación detectada\n",
    "df_train = pd.read_csv(nombre_archivo, encoding=result['encoding'])\n",
    "print(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cb047d-844d-41e9-9621-97891e2ed627",
   "metadata": {},
   "source": [
    "### Le asigno un nombre a la primer columna (no tiene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8db45b8a-0fc5-4f93-afdb-64648054418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignar un nombre temporal a la primera columna\n",
    "df_train.columns = ['Material-Imagen'] + df_train.columns[1:].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d908d09-45ca-4502-a6b5-3e3f6a56edc9",
   "metadata": {},
   "source": [
    "### Inspeccion rapida de los datos: analizo cuantos ejemplos hay de cada tipo de Clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a3775c-887b-410e-9997-3fad7bc66568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para hacer una inspección rápida de los datos\n",
    "#print(df.head())\n",
    "#print(df.describe())\n",
    "df_train['Material-Imagen'].hist(bins=7)\n",
    "\n",
    "PREGUNTAR!!!!!!!!\n",
    "(EN EJERCICIO ANTERIOR ME FUNCIONO BIEN Y TAMBIEN ERA UNA COLUMNA CON NOMBRES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765edcb2-3712-46b2-ad9d-80c8eff1e4af",
   "metadata": {},
   "source": [
    "### Datos de testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97a775a3-bc60-47df-83bd-ca042a9af1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           REGION-CENTROID-COL  REGION-CENTROID-ROW  REGION-PIXEL-COUNT  \\\n",
      "BRICKFACE                140.0                125.0                   9   \n",
      "BRICKFACE                188.0                133.0                   9   \n",
      "BRICKFACE                105.0                139.0                   9   \n",
      "BRICKFACE                 34.0                137.0                   9   \n",
      "BRICKFACE                 39.0                111.0                   9   \n",
      "...                        ...                  ...                 ...   \n",
      "GRASS                     36.0                243.0                   9   \n",
      "GRASS                    186.0                218.0                   9   \n",
      "GRASS                    197.0                236.0                   9   \n",
      "GRASS                    208.0                240.0                   9   \n",
      "GRASS                    223.0                185.0                   9   \n",
      "\n",
      "           SHORT-LINE-DENSITY-5  SHORT-LINE-DENSITY-2  VEDGE-MEAN  VEDGE-SD  \\\n",
      "BRICKFACE              0.000000                   0.0    0.277778  0.062963   \n",
      "BRICKFACE              0.000000                   0.0    0.333333  0.266667   \n",
      "BRICKFACE              0.000000                   0.0    0.277778  0.107407   \n",
      "BRICKFACE              0.000000                   0.0    0.500000  0.166667   \n",
      "BRICKFACE              0.000000                   0.0    0.722222  0.374074   \n",
      "...                         ...                   ...         ...       ...   \n",
      "GRASS                  0.111111                   0.0    1.888889  1.851851   \n",
      "GRASS                  0.000000                   0.0    1.166667  0.744444   \n",
      "GRASS                  0.000000                   0.0    2.444444  6.829628   \n",
      "GRASS                  0.111111                   0.0    1.055556  0.862963   \n",
      "GRASS                  0.000000                   0.0    0.500000  0.349603   \n",
      "\n",
      "           HEDGE-MEAN  HEDGE-SD  INTENSITY-MEAN  RAWRED-MEAN  RAWBLUE-MEAN  \\\n",
      "BRICKFACE    0.666667  0.311111        6.185185     7.333334      7.666666   \n",
      "BRICKFACE    0.500000  0.077778        6.666666     8.333334      7.777778   \n",
      "BRICKFACE    0.833333  0.522222        6.111111     7.555555      7.222222   \n",
      "BRICKFACE    1.111111  0.474074        5.851852     7.777778      6.444445   \n",
      "BRICKFACE    0.888889  0.429629        6.037037     7.000000      7.666666   \n",
      "...               ...       ...             ...          ...           ...   \n",
      "GRASS        2.000000  0.711110       13.333333     9.888889     12.111111   \n",
      "GRASS        1.166667  0.655555       13.703704    10.666667     12.666667   \n",
      "GRASS        3.333333  7.599998       16.074074    13.111111     16.666668   \n",
      "GRASS        2.444444  5.007407       14.148149    10.888889     13.000000   \n",
      "GRASS        2.388889  2.080776       12.962963    11.555555      9.777778   \n",
      "\n",
      "           RAWGREEN-MEAN  EXRED-MEAN  EXBLUE-MEAN  EXGREEN-MEAN  VALUE-MEAN  \\\n",
      "BRICKFACE       3.555556    3.444444     4.444445     -7.888889    7.777778   \n",
      "BRICKFACE       3.888889    5.000000     3.333333     -8.333333    8.444445   \n",
      "BRICKFACE       3.555556    4.333334     3.333333     -7.666666    7.555555   \n",
      "BRICKFACE       3.333333    5.777778     1.777778     -7.555555    7.777778   \n",
      "BRICKFACE       3.444444    2.888889     4.888889     -7.777778    7.888889   \n",
      "...                  ...         ...          ...           ...         ...   \n",
      "GRASS          18.000000  -10.333333    -3.666667     14.000000   18.000000   \n",
      "GRASS          17.777779   -9.111111    -3.111111     12.222222   17.777779   \n",
      "GRASS          18.444445   -8.888889     1.777778      7.111111   18.555555   \n",
      "GRASS          18.555555   -9.777778    -3.444444     13.222222   18.555555   \n",
      "GRASS          17.555555   -4.222222    -9.555555     13.777778   17.555555   \n",
      "\n",
      "           SATURATION-MEAN  HUE-MEAN  \n",
      "BRICKFACE         0.545635 -1.121818  \n",
      "BRICKFACE         0.538580 -0.924817  \n",
      "BRICKFACE         0.532628 -0.965946  \n",
      "BRICKFACE         0.573633 -0.744272  \n",
      "BRICKFACE         0.562919 -1.175773  \n",
      "...                    ...       ...  \n",
      "GRASS             0.452229  2.368311  \n",
      "GRASS             0.401347  2.382684  \n",
      "GRASS             0.292729  2.789800  \n",
      "GRASS             0.421621  2.392487  \n",
      "GRASS             0.445418  1.838850  \n",
      "\n",
      "[210 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nombre_archivo = DATOS_DIR + 'Segment_Test.csv' \n",
    "\n",
    "#-- detectando la codificación de caracteres usada ----\n",
    "with open(nombre_archivo, 'rb') as f:\n",
    "    result = chardet.detect(f.read())  # or readline if the file is large\n",
    "\n",
    "# recupera el archivo en un objeto dataframe de pandas utilizando la codificación detectada\n",
    "df_test = pd.read_csv(nombre_archivo, encoding=result['encoding'])\n",
    "print(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f1af49-51e8-471f-96c8-8d59737505ff",
   "metadata": {},
   "source": [
    "### Consigna"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a3c1325c-a29b-43ed-99ac-be7e9318a0a4",
   "metadata": {},
   "source": [
    "Entrene una red neuronal multiperceptrón para que dada una región de 3x3, representada a través de \n",
    "los 19 atributos indicados anteriormente, sea capaz de identificar a cuál de las 7 imágenes corresponde. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627dba7d-ad0a-4d49-8e32-a67fc2cfb037",
   "metadata": {},
   "source": [
    "### Entrenamiento (utilizo df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "30f00c11-3396-4668-a49a-55090fa71c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las clases del dataset son : [  1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.  14.\n",
      "  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.  28.\n",
      "  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.  42.\n",
      "  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.  56.\n",
      "  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.  70.\n",
      "  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.  84.\n",
      "  85.  86.  87.  88.  89.  90.  91.  92.  93.  94.  95.  96.  97.  98.\n",
      "  99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111. 112.\n",
      " 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124. 125. 126.\n",
      " 127. 128. 129. 130. 131. 132. 133. 134. 135. 136. 137. 138. 139. 140.\n",
      " 141. 142. 143. 144. 145. 146. 147. 148. 149. 150. 151. 152. 153. 154.\n",
      " 155. 156. 157. 158. 159. 160. 161. 162. 163. 164. 165. 166. 167. 168.\n",
      " 169. 170. 171. 172. 173. 174. 175. 176. 177. 178. 179. 180. 181. 182.\n",
      " 183. 184. 185. 186. 187. 188. 189. 190. 191. 192. 193. 194. 195. 196.\n",
      " 197. 198. 199. 200. 201. 202. 203. 204. 205. 206. 207. 208. 209. 210.\n",
      " 211. 212. 213. 214. 215. 216. 217. 218. 219. 220. 221. 222. 223. 224.\n",
      " 225. 226. 227. 228. 229. 230. 231. 232. 233. 234. 235. 236. 237. 238.\n",
      " 239. 240. 241. 242. 243. 244. 245. 247. 248. 249. 250. 251. 252. 253.\n",
      " 254.]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# %% separa atributos y clases\n",
    "X_train = np.array(df_train.iloc[:,1:])  # recupera todas las columnas salvo la primera \n",
    "Y_train = np.array(df_train.iloc[:,0])    # recupera solo la primer columna (valor a predecir)\n",
    "\n",
    "# Binarizador para convertir el nombre de la clase en one hot encoding\n",
    "binarizer = preprocessing.LabelBinarizer()\n",
    "\n",
    "# Binariza cada clase como una combinación de un 1 y 0s\n",
    "Y_train = binarizer.fit_transform(Y_train)\n",
    "# Y_raw==pd.get_dummies(df[' Balance']).to_numpy() # forma alternativa para codificar\n",
    "\n",
    "print('Las clases del dataset son :', binarizer.classes_)\n",
    "print(Y_train)\n",
    "# Escala los atributos de los ejemplo\n",
    "scaler = preprocessing.StandardScaler()\n",
    "#scaler = preprocessing.MinMaxScaler()\n",
    "X_train  = scaler.fit_transform( X_train )\n",
    "\n",
    "################################################### En este caso no dividio el df en train y test porque tengo 2 dfs\n",
    "# %% Separa ejemplos para enternamiento y testeo:\n",
    "#TEST_SIZE = 0.30 # proporcion entre testeo entre entrenamiento y testeo (utiliza 30% de los datos para testeo y el otro 70% de los datos para entrenamiento)\n",
    "# X_test e Y_test --> datos de testeo (x atributos, y valores a predecir) --> 30% del dataset\n",
    "# X_train e Y_train --> datos de entrenamiento --> 70% del dataset\n",
    "\n",
    "#X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X_raw, Y_raw, test_size=TEST_SIZE)#, random_state=42)\n",
    "\n",
    "#print('\\nDatos de Entrenamiento: %d   Datos de Testeo: %d' % (len(Y_train), len(Y_test) ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3756d6a-b046-4d34-a657-f2e110fcecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FunH = 'tanh'   # identity logistic tanh relu\n",
    "ocultas = (8)\n",
    "\n",
    "alfa = 0.005\n",
    "CotaError = 1.0e-5\n",
    "MAX_ITE = 100\n",
    "\n",
    "modelo = MLPClassifier(max_iter=MAX_ITE, hidden_layer_sizes=ocultas, alpha=alfa,\n",
    "                       solver='sgd', activation=FunH, tol=CotaError,\n",
    "                       verbose=False).fit(X_train, Y_train)\n",
    "\n",
    "modelo.out_activation_ = 'softmax'\n",
    "\n",
    "#  ########### Medición del entrenamiento ######################\n",
    "# entrenamiento con X_train e Y_train (80% del dataset)\n",
    "Y_pred = modelo.predict(X_train)\n",
    "score = modelo.score(X_train, Y_train)\n",
    "\n",
    "# \"invierte\" la transformacion binaria para obtener los nombres de las clases\n",
    "Y_it = binarizer.inverse_transform(Y_train)\n",
    "Y_pred_it = binarizer.inverse_transform(Y_pred)\n",
    "\n",
    "# calculo manual del accuracy\n",
    "print('Efectividad: %6.2f%%' % (100*(Y_pred_it == Y_it).sum()/len(Y_it)) )\n",
    "print('      Score: %6.2f%%' % (score) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911c4ae2-757a-4d0d-92d1-2813039e5bde",
   "metadata": {},
   "source": [
    "### Testeo (utilizo df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f5edf5-213b-4648-b559-b83a7ba6ccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% separa atributos y clases\n",
    "X_test = np.array(df_test.iloc[:,1:])  # recupera todas las columnas salvo la primera \n",
    "Y_test = np.array(df_test.iloc[:,0])    # recupera solo la primer columna (valor a predecir)\n",
    "\n",
    "#  ########### Medición del testeo ######################\n",
    "Y_pred = modelo.predict(X_test)\n",
    "score = modelo.score(X_test, Y_test)\n",
    "\n",
    "# \"invierte\" la transformacion binaria para obtener los nombres de las clases ---> no es necesario pq no binarice el df_test\n",
    "Y_it = binarizer.inverse_transform(Y_test)\n",
    "Y_pred_it = binarizer.inverse_transform(Y_pred)\n",
    "\n",
    "# calculo manual del accuracy\n",
    "print('Efectividad: %6.2f%%' % (100*(Y_pred_it == Y_it).sum()/len(Y_it)) )\n",
    "print('      Score: %6.2f%%' % (score) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9074765d-0253-41df-8b3d-b6a6fb7874a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREGUNTAR QUE ESTOY HACIENDO MAL O SI SE ESTA LEYENDO MAL EL DF: EN LA CONSIGNA \n",
    "DICE QUE EL ATRIBUTO 20. ES UN NRO QUE INDICA Q MATERIAL ES. PERO NO ES ASI.\n",
    "EL PRIMER ATRIBUTO SON LOS NOMBRES DEL MATERIAL, EL TEMA ES QUE CUANDO TOMO LA \"PRIMER COLUMNA\" PARA EL TRAIN\n",
    "ME TOMA A PARTIR DE LA SEGUNDA ¿?\n",
    "TAMBIEN HAY ERROR EN EL HISTOGRAMA!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
